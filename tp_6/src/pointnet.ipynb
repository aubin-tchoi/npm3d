{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# NPM3D - Deep learning based approaches (PointNet)"
   ],
   "metadata": {
    "id": "4nIg-2VKb3jx",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title Imports\n",
    "\n",
    "import math\n",
    "import os\n",
    "import random\n",
    "from functools import wraps\n",
    "from time import perf_counter\n",
    "from typing import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title Drive mounting\n",
    "\n",
    "is_on_colab = False #@param {type:\"boolean\"}\n",
    "\n",
    "if is_on_colab:\n",
    "  try:\n",
    "      from google.colab import drive\n",
    "\n",
    "      drive.mount(\"/content/drive\", force_remount=True)\n",
    "  except ImportError:\n",
    "      pass\n",
    "\n",
    "  folder_path = \"\\\"/content/drive/MyDrive/master/mva/s2/npm3d/TP6_materials/code/\\\"\" #@param {type:\"string\"}\n",
    "  os.chdir(folder_path)\n",
    "\n",
    "from ply import read_ply"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title Performance monitoring\n",
    "\n",
    "\n",
    "def timeit(func: Callable) -> Callable:\n",
    "    \"\"\"\n",
    "    Decorator for timing function execution time.\n",
    "\n",
    "    Args:\n",
    "      func: The function to time.\n",
    "\n",
    "    Returns:\n",
    "      The wrapped function.\n",
    "    \"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def timeit_wrapper(*args, **kwargs):\n",
    "        start_time = perf_counter()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = perf_counter()\n",
    "        total_time = end_time - start_time\n",
    "        print(f\"Function {func.__name__} took {total_time:.2f} seconds\")\n",
    "        return result\n",
    "\n",
    "    return timeit_wrapper\n",
    "\n",
    "\n",
    "def checkpoint(time_ref: float = perf_counter()) -> Callable[..., None]:\n",
    "    \"\"\"\n",
    "    Closure that stores a time checkpoint that is updated at every call.\n",
    "    Each call prints the time elapsed since the last checkpoint with a custom message.\n",
    "\n",
    "    Args:\n",
    "      time_ref: The time reference to start from. By default, the time of the call will be taken.\n",
    "    Returns:\n",
    "      The closure.\n",
    "    \"\"\"\n",
    "\n",
    "    def _closure(message: str = \"\") -> None:\n",
    "        \"\"\"\n",
    "        Prints the time elapsed since the previous call.\n",
    "\n",
    "        Args:\n",
    "          message: Custom message to print. The overall result will be: 'message: time_elapsed'.\n",
    "        \"\"\"\n",
    "        nonlocal time_ref\n",
    "        current_time = perf_counter()\n",
    "        if message != \"\":\n",
    "            print(f\"{message}: {current_time - time_ref:.4f}\")\n",
    "        time_ref = current_time\n",
    "\n",
    "    return _closure"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data augmentation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class RandomRotationZ(object):\n",
    "    def __call__(self, point_cloud):\n",
    "        theta = random.random() * 2.0 * math.pi\n",
    "        rot_matrix = np.array(\n",
    "            [\n",
    "                [math.cos(theta), -math.sin(theta), 0],\n",
    "                [math.sin(theta), math.cos(theta), 0],\n",
    "                [0, 0, 1],\n",
    "            ]\n",
    "        )\n",
    "        rot_point_cloud = rot_matrix.dot(point_cloud.T).T\n",
    "        return rot_point_cloud\n",
    "\n",
    "\n",
    "class RandomRotationY(object):\n",
    "    def __call__(self, point_cloud):\n",
    "        theta = random.random() * 2.0 * math.pi\n",
    "        rot_matrix = np.array(\n",
    "            [\n",
    "                [math.cos(theta), 0, -math.sin(theta)],\n",
    "                [0, 1, 0],\n",
    "                [math.sin(theta), 0, math.cos(theta)],\n",
    "            ]\n",
    "        )\n",
    "        rot_point_cloud = rot_matrix.dot(point_cloud.T).T\n",
    "        return rot_point_cloud\n",
    "\n",
    "\n",
    "class RandomRotationX(object):\n",
    "    def __call__(self, point_cloud):\n",
    "        theta = random.random() * 2.0 * math.pi\n",
    "        rot_matrix = np.array(\n",
    "            [\n",
    "                [1, 0, 0],\n",
    "                [0, math.cos(theta), -math.sin(theta)],\n",
    "                [0, math.sin(theta), math.cos(theta)],\n",
    "            ]\n",
    "        )\n",
    "        rot_point_cloud = rot_matrix.dot(point_cloud.T).T\n",
    "        return rot_point_cloud\n",
    "\n",
    "\n",
    "class RandomNoise(object):\n",
    "    def __call__(self, point_cloud):\n",
    "        noise = np.random.normal(0, 0.02, (point_cloud.shape))\n",
    "        noisy_point_cloud = point_cloud + noise\n",
    "        return noisy_point_cloud\n",
    "\n",
    "\n",
    "class RandomSymmetry(object):\n",
    "    def __call__(self, point_cloud, probability=0.5):\n",
    "        axis = random.randint(0, 1)  # random axis among x and y\n",
    "        if torch.rand(1) < probability:\n",
    "            c_max = np.max(point_cloud[:, axis])\n",
    "            point_cloud[:, axis] = c_max - point_cloud[:, axis]\n",
    "        return point_cloud\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, point_cloud):\n",
    "        return torch.Tensor(point_cloud)\n",
    "\n",
    "\n",
    "def default_transforms():\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            RandomRotationZ(),\n",
    "            RandomNoise(),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def custom_transforms():\n",
    "    return transforms.Compose(\n",
    "        [\n",
    "            RandomSymmetry(),\n",
    "            RandomRotationZ(),\n",
    "            RandomRotationY(),\n",
    "            RandomRotationX(),\n",
    "            RandomNoise(),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def test_transforms():\n",
    "    return transforms.Compose([ToTensor()])\n",
    "\n",
    "\n",
    "class PointCloudDataRAM(Dataset):\n",
    "    def __init__(self, root_dir, folder=\"train\", transform=default_transforms()):\n",
    "        self.root_dir = root_dir\n",
    "        folders = [\n",
    "            directory\n",
    "            for directory in sorted(os.listdir(root_dir))\n",
    "            if os.path.isdir(root_dir + \"/\" + directory)\n",
    "        ]\n",
    "        self.classes = {folder: i for i, folder in enumerate(folders)}\n",
    "        self.transforms = transform\n",
    "        self.data = []\n",
    "        timer = checkpoint()\n",
    "        for category in self.classes.keys():\n",
    "            new_dir = root_dir + \"/\" + category + \"/\" + folder\n",
    "            for file in os.listdir(new_dir):\n",
    "                if file.endswith(\".ply\"):\n",
    "                    ply_path = new_dir + \"/\" + file\n",
    "                    data = read_ply(ply_path)\n",
    "                    sample = {\n",
    "                        \"point_cloud\": np.vstack((data[\"x\"], data[\"y\"], data[\"z\"])).T,\n",
    "                        \"category\": self.classes[category],\n",
    "                    }\n",
    "                    self.data.append(sample)\n",
    "            timer(f\"Time spent on category {category}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        point_cloud = self.transforms(self.data[idx][\"point_cloud\"])\n",
    "        return {\"point_cloud\": point_cloud, \"category\": self.data[idx][\"category\"]}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super(MLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(3072, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class PointNetBasic(nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.MaxPool1d(1024),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, classes),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class Tnet(nn.Module):\n",
    "    def __init__(self, k=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.MaxPool1d(1024),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, k * k),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "class PointNetFull(nn.Module):\n",
    "    def __init__(self, classes=10):\n",
    "        super().__init__()\n",
    "        self.t_net = Tnet()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv1d(3, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 64, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Conv1d(64, 128, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Conv1d(128, 1024, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.MaxPool1d(1024),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, classes),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        t_net_transform = self.t_net(x).view(-1, 3, 3) + torch.eye(3).to(device)\n",
    "        return self.net(t_net_transform @ x), t_net_transform"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Losses and pipelines"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def basic_loss(outputs, labels):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    return criterion(outputs, labels)\n",
    "\n",
    "\n",
    "def pointnet_full_loss(outputs, labels, m3x3, alpha=0.001):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    bs = outputs.size(0)\n",
    "    id3x3 = torch.eye(3, requires_grad=True).repeat(bs, 1, 1)\n",
    "    if outputs.is_cuda:\n",
    "        id3x3 = id3x3.cuda()\n",
    "    diff3x3 = id3x3 - torch.bmm(m3x3, m3x3.transpose(1, 2))\n",
    "    return criterion(outputs, labels) + alpha * (torch.norm(diff3x3)) / float(bs)\n",
    "\n",
    "\n",
    "def train(model, device, train_loader, test_loader=None, epochs=250):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "    loss = 0\n",
    "    train_loss, test_accuracy = [], []\n",
    "    for epoch in range(epochs):\n",
    "        try:\n",
    "            total_loss, total = 0., 0\n",
    "            model.train()\n",
    "            for i, data in enumerate(train_loader, 0):\n",
    "\n",
    "                inputs, labels = data[\"point_cloud\"].to(device).float(), data[\n",
    "                    \"category\"\n",
    "                ].to(device)\n",
    "                optimizer.zero_grad()\n",
    "                if model.__class__.__name__ == \"PointNetFull\":\n",
    "                  outputs, m3x3 = model(inputs.transpose(1, 2))\n",
    "                  loss = pointnet_full_loss(outputs, labels, m3x3)\n",
    "                else:\n",
    "                  outputs = model(inputs.transpose(1,2))\n",
    "                  loss = basic_loss(outputs, labels)\n",
    "                total_loss += loss.item()\n",
    "                total += 1\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            scheduler.step()\n",
    "            train_loss.append(total_loss / total)\n",
    "\n",
    "            model.eval()\n",
    "            correct = total = 0\n",
    "            if test_loader:\n",
    "                with torch.no_grad():\n",
    "                    for data in test_loader:\n",
    "                        inputs, labels = data[\"point_cloud\"].to(device).float(), data[\n",
    "                            \"category\"\n",
    "                        ].to(device)\n",
    "                        if model.__class__.__name__ == \"PointNetFull\":\n",
    "                            outputs, __ = model(inputs.transpose(1, 2))\n",
    "                        else:\n",
    "                            outputs = model(inputs.transpose(1,2))\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        total += labels.size(0)\n",
    "                        correct += (predicted == labels).sum().item()\n",
    "                test_acc = 100.0 * correct / total\n",
    "                print(\n",
    "                    \"Epoch: %d, Loss: %.3f, Test accuracy: %.1f %%\"\n",
    "                    % (epoch + 1, loss, test_acc)\n",
    "                )\n",
    "                test_accuracy.append(test_acc)\n",
    "\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Training interrupted.\")\n",
    "            break\n",
    "\n",
    "    return train_loss, test_accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot_performance(train_loss, test_accuracy) -> None:\n",
    "    \"\"\"\n",
    "    Plots two graphs describing the evolution of two metrics during the training process.\n",
    "    \"\"\"\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(11, 5))\n",
    "\n",
    "    ax1.plot(train_loss)\n",
    "    ax1.set_title(\"Model loss on training set\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.set_xlabel(\"Epoch\")\n",
    "\n",
    "    ax2.plot(test_accuracy)\n",
    "    ax2.set_title(\"Model accuracy on validation set\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Experiments"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timer = checkpoint()\n",
    "\n",
    "ROOT_DIR = \"../data/ModelNet10_PLY\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "train_ds = PointCloudDataRAM(ROOT_DIR, folder=\"train\", transform=default_transforms())\n",
    "test_ds = PointCloudDataRAM(ROOT_DIR, folder=\"test\", transform=test_transforms())\n",
    "\n",
    "inv_classes = {i: cat for cat, i in train_ds.classes.items()}\n",
    "print(\"Classes: \", inv_classes)\n",
    "print(\"Train dataset size: \", len(train_ds))\n",
    "print(\"Test dataset size: \", len(test_ds))\n",
    "print(\"Number of classes: \", len(train_ds.classes))\n",
    "print(\"Sample point_cloud shape: \", train_ds[0][\"point_cloud\"].size())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=32)\n",
    "\n",
    "timer(\"Time spent on dataloader initialization\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timer()\n",
    "\n",
    "model = MLP() #@param [\"MLP()\", \"PointNetBasic()\", \"PointNetFull()\"] {type:\"raw\"}\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(f\"Using a {model.__class__.__name__} with {sum(np.prod(p.size()) for p in model_parameters)} parameters\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "mlp_train_loss, mlp_test_accuracy = train(model, device, train_loader, test_loader, epochs=75)\n",
    "\n",
    "timer(\"Time spent on training\")\n",
    "plot_performance(mlp_train_loss, mlp_test_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timer()\n",
    "\n",
    "model = PointNetBasic() #@param [\"MLP()\", \"PointNetBasic()\", \"PointNetFull()\"] {type:\"raw\"}\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(f\"Using a {model.__class__.__name__} with {sum(np.prod(p.size()) for p in model_parameters)} parameters\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "ptb_train_loss, ptb_test_accuracy = train(model, device, train_loader, test_loader, epochs=75)\n",
    "\n",
    "timer(\"Time spent on training\")\n",
    "plot_performance(ptb_train_loss, ptb_test_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timer()\n",
    "\n",
    "model = PointNetFull() #@param [\"MLP()\", \"PointNetBasic()\", \"PointNetFull()\"] {type:\"raw\"}\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(f\"Using a {model.__class__.__name__} with {sum(np.prod(p.size()) for p in model_parameters)} parameters\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "pt_train_loss, pt_test_accuracy = train(model, device, train_loader, test_loader, epochs=75)\n",
    "\n",
    "timer(\"Time spent on training\")\n",
    "plot_performance(pt_train_loss, pt_test_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timer = checkpoint()\n",
    "\n",
    "ROOT_DIR = \"../data/ModelNet10_PLY\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device\", device)\n",
    "\n",
    "train_ds = PointCloudDataRAM(ROOT_DIR, folder=\"train\", transform=custom_transforms())\n",
    "test_ds = PointCloudDataRAM(ROOT_DIR, folder=\"test\", transform=custom_transforms())\n",
    "\n",
    "inv_classes = {i: cat for cat, i in train_ds.classes.items()}\n",
    "print(\"Classes: \", inv_classes)\n",
    "print(\"Train dataset size: \", len(train_ds))\n",
    "print(\"Test dataset size: \", len(test_ds))\n",
    "print(\"Number of classes: \", len(train_ds.classes))\n",
    "print(\"Sample point_cloud shape: \", train_ds[0][\"point_cloud\"].size())\n",
    "\n",
    "train_loader = DataLoader(dataset=train_ds, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_ds, batch_size=32)\n",
    "\n",
    "timer(\"Time spent on dataloader initialization\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "timer()\n",
    "\n",
    "model = PointNetBasic() #@param [\"MLP()\", \"PointNetBasic()\", \"PointNetFull()\"] {type:\"raw\"}\n",
    "\n",
    "model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "print(f\"Using a {model.__class__.__name__} with {sum(np.prod(p.size()) for p in model_parameters)} parameters\")\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "pta_train_loss, pta_test_accuracy = train(model, device, train_loader, test_loader, epochs=500)\n",
    "\n",
    "timer(\"Time spent on training\")\n",
    "plot_performance(pta_train_loss, pta_test_accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "colab": {
   "provenance": []
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
